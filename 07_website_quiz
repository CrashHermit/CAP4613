| No. | Question | Ans |
|---|---|---|
| 1 | **Deep-Reinforcement Learning >> Convolutional Neural Network** QNo. 1: What are the examples of more popular CNN architectures used in computer vision tasks? A. Naive Bayes, Decision Tree, Logistic Regression, and Random Forest designed for high-dimensional visual input classification. B. GRU, LSTM, Transformer, and BERT optimized for capturing spatial patterns in visual data through convolution layers. C. K-Means, PCA, DBSCAN, and GMM used for hierarchical feature extraction in image-based reinforcement learning systems. D. AlexNet, VGG, ResNet, and Inception built for deep feature extraction and classification in image recognition tasks. | B |
| | **Explanantion:** $\checkmark$ Explanation of Correct Answer (B): CNNs reduce parameter count through weight sharing and preserve spatial relationships, making them ideal for processing high-dimensional image inputs efficiently. $\times$ Explanation of Distractors: A: Incorrect — Fully connected networks do not fail due to excess activation functions, the issue lies in parameter inefficiency and loss of spatial structure. B: Incorrect — Both CNNs and fully connected networks typically rely on labeled data for supervised learning; unsupervised use is limited and not architecture-specific. C: Incorrect — CNNs eliminate manual feature extraction using convolution layers, not by integrating reinforcement learning techniques directly. | |
| 2 | **Deep-Reinforcement Learning >> Convolutional Neural Network** QNo. 2: What are the examples of more popular CNN architectures used in computer vision tasks? A. Naive Bayes, Decision Tree, Logistic Regression, and Random Forest designed for high-dimensional visual input classification. B. GRU, LSTM, Transformer, and BERT optimized for capturing spatial patterns in visual data through convolution layers. C. K-Means, PCA, DBSCAN, and GMM used for hierarchical feature extraction in image-based reinforcement learning systems. D. AlexNet, VGG, ResNet, and Inception built for deep feature extraction and classification in image recognition tasks. | D |
| | **Explanantion:** $\checkmark$ Explanation of Correct Answer (D): AlexNet, VGG, ResNet, and Inception are landmark CNN architectures widely used for image classification and feature learning in computer vision. $\times$ Explanation of Distractors: A: Incorrect — These are traditional machine learning models, not CNNs, and are often not suited for raw image input processing. B: Incorrect — These are recurrent and transformer models, mainly used for sequential data like text or time series, not visual input. C: Incorrect — These are clustering and dimensionality reduction techniques, not the specific model architectures used in CNN-based image processing. | |
| 3 | **Deep-Reinforcement Learning >> Convolutional Neural Network** QNo. 3: Why are CNNs suitable for visual input in reinforcement learning environments? A. CNNs replicate entire images as input, which helps the agent memorize state space rather than generalize across similar visual scenes. B. CNNs extract spatial features efficiently, allowing the agent to recognize patterns and objects in complex visual observations. C. CNNs generate random image filters, enabling reinforcement learning agents to explore actions without needing structured visual input. D. CNNs increase pixel-level accuracy, ensuring exact reproduction of visual scenes from frame to frame in the environment. | B |
| | **Explanantion:** $\checkmark$ Explanation of Correct Answer (B): CNNs detect spatial hierarchies in images, enabling agents to understand and act based on important visual features like objects, shapes, and movement. $\times$ Explanation of Distractors: A: Incorrect — CNNs generalize visual patterns instead of memorizing entire images, improving performance across varied environments. C: Incorrect — CNNs learn structured filters from data, not random ones, to recognize meaningful spatial information in visual inputs. D: Incorrect — CNNs are not designed for pixel-perfect reproduction but for understanding the visual context through feature abstraction. | |
| 4 | **Deep-Reinforcement Learning >> Convolutional Neural Network** QNo. 4: What roles do pooling and activation functions play in Convolutional Neural Networks (CNNs)? A. Pooling simplifies feature maps by reducing spatial size, and activation functions introduce non-linearity to help CNNs learn complex patterns in data. B. Pooling increases feature map size, and activation functions keep all values positive, which is a positive for stable weight initialization in CNNs. C. Pooling layers remove all redundant data, and activation functions ensure the network remains fully linear during learning phases. D. Pooling adds layers of noise to features, while activation functions randomly select which neurons are active in each layer. | A |
| | **Explanantion:** $\checkmark$ Correct Answer: A $\checkmark$ Explanation of Correct Answer (A): Pooling simplifies feature maps by reducing spatial size, and activation functions introduce non-linearity to learn complex, non-linear relationships in data. $\times$ Explanation of Distractors: B: Incorrect — Pooling decreases, not increases, spatial dimensions; activation functions do more than just keeping values positive. C: Incorrect — Pooling simplifies, not removes all data; activation functions introduce non-linearity, not maintain linearity. D: Incorrect — Pooling reduces noise, not adds it; activation functions are deterministic, not random neuron selectors. | |
| 5 | **Deep-Reinforcement Learning >> Convolutional Neural Network** QNo. 5: How does a Convolutional Neural Network (CNN) differ from a fully connected neural network? A. CNNs use convolutional layers to capture spatial features, while fully connected networks treat all inputs equally. B. CNNs connect all neurons to each other, while fully connected networks use only local filters for input. C. CNNs require manual feature extraction, while fully connected networks learn features through convolutional layers. D. CNNs cannot be used for image tasks, while fully connected networks perform better on spatial data. | A |
| | **Explanantion:** $\checkmark$ Explanation of Correct Answer (A): CNNs use local receptive fields and shared weights to extract spatial features, unlike fully connected networks that treat all input connections equally. $\times$ Explanation of Distractors: B: Incorrect — CNNs typically use fewer parameters due to shared weights, making them more efficient than fully connected layers. C: Incorrect — CNNs are specifically designed to capture spatial relationships, unlike fully connected networks that ignore spatial layout. D: Incorrect — CNNs are especially suited for image and spatial data, while fully connected networks are more general-purpose but less efficient for such tasks. | |