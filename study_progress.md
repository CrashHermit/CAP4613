# Study Progress Tracker

## Quiz 07: Convolutional Neural Networks (CNNs)
- **Status**: In Progress
- **Score**: 1/15 completed (1 correct)
- **Last Reviewed**: Current session

### Question Results

#### ✅ Question 1: How does a CNN differ from a fully connected network?
- **Status**: CORRECT (after guidance)
- **Student Answer**: "CNNS have layers of filters that all feed into each other, whereas a fully connected network has layers but it doesn't have filters" → "With fcn the neruons connect everywhere and in the cnn the neuroens are connected to the next local input" → "It uses the same weights at each position"
- **Attempts**: 3 (progressive understanding)
- **Key Points Covered**:
  - ✅ Local connectivity (receptive fields) - neurons connect to local regions only
  - ✅ Parameter sharing (same filter weights reused across entire image)
  - ✅ Efficiency: dramatically fewer parameters than FCNs
- **Areas to Review**: None - solid understanding achieved
- **Flashcard Ready**: Yes

#### ✅ Question 2: What roles do pooling and activation functions play?
- **Status**: CORRECT
- **Key Points Covered**:
  - ✅ Pooling: Reduces spatial dimensions (2×2 window)
  - ✅ Pooling benefits: Fewer parameters, lower computational cost, filters irrelevant details
  - ✅ Pooling: Provides translation invariance (recognizes features in different positions)
  - ✅ Activation functions: Introduce non-linearity (enables learning complex patterns)
- **Areas to Review**: None - excellent understanding
- **Flashcard Ready**: Yes

#### ✅ Question 3: Why are CNNs suitable for visual input in RL?
- **Status**: CORRECT (with guidance)
- **Key Points Covered**:
  - ✅ Spatial hierarchy: Builds complexity from edges → shapes → objects
  - ✅ Automatic feature extraction: Understands environment without manual engineering
  - ✅ Translation invariance: Recognizes features regardless of position (critical in dynamic RL environments)
- **Areas to Review**: Could benefit from mentioning parameter efficiency and scalability
- **Flashcard Ready**: Yes

#### ✅ Question 4: What are popular CNN architectures?
- **Status**: CORRECT
- **Key Points Covered**:
  - ✅ AlexNet: First to use ReLU activation; won ImageNet 2012
  - ✅ ResNet: Uses skip/residual connections; enables training of very deep networks (152+ layers); solves vanishing gradient problem
  - ✅ VGG: Stacks many 3×3 convolutional filters in uniform structure
- **Areas to Review**: None - good understanding of key architectures
- **Flashcard Ready**: Yes

#### ⏳ Question 5: Why did CNNs replace fully connected networks?
- **Status**: Not yet answered

---

## Quiz 08: Recurrent Neural Networks (RNNs)
- **Status**: Not started
- **Score**: 0/0

## Quiz 09: Recursive Neural Networks (RvNNs)
- **Status**: Not started
- **Score**: 0/0

## Quiz 10: Reinforcement Learning Fundamentals
- **Status**: Not started
- **Score**: 0/0

## Quiz 11: Dynamic Programming
- **Status**: Not started
- **Score**: 0/0

## Quiz 12: Monte Carlo & Temporal Difference
- **Status**: Not started
- **Score**: 0/0

---

## Areas Needing More Study
_(Will be populated as you progress)_

---

## Flashcard Generation Log
_(Will be created after completing quizzes)_
