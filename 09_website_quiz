| No. | Question | Ans |
|---|---|---|
| 1 | **Deep-Reinforcement Learning >> Recursive Neural Network** QNo. 1: What are the main limitations or challenges in training Recursive Neural Networks? A. They require sequential inputs with fixed length, limiting their ability to process structured or variable-length data like trees or graphs. B. They are inefficient for low-dimensional data and cannot generalize to large-scale inputs due to poor feature extraction capabilities. C. They depend on large labeled datasets with time-aligned sequences to perform temporal learning across multiple recurrent layers. D. They rely on external tree structures and are computationally intensive due to complex backpropagation through hierarchical nodes. | D |
| | **Explanantion:** $\checkmark$ Explanation of Correct Answer (D): Training RVNNs is challenging because they need syntactic or structural trees as input, and they require recursive backpropagation, which increases complexity and slows down computation compared to simpler models. $\times$ Explanation of Distractors: A: Incorrect — This describes RNNs, which process fixed-length sequences, not RVNNs, which are good at variable-length tree structures. B: Incorrect — This applies more to basic feedforward networks, not RVNNs, which are good at learning compositional representations. C: Incorrect — This confuses RVNNs with RNNs, which are designed for temporal sequences, not tree structures. | |
| 2 | **Deep-Reinforcement Learning >> Recursive Neural Network** QNo. 2: How is backpropagation performed in a recursive neural network (Backpropagation Through Structure)? A. Gradients are passed sequentially across time steps using temporal dependencies established in the forward pass, as in recurrent neural networks. B. Errors are propagated through convolutional layers using filters applied at each level of a spatial hierarchy to refine features. C. Weight updates are computed layer by layer from output to input, following the standard feedforward backpropagation method. D. Gradients are recursively propagated from parent nodes to child nodes following the tree structure, aligning with the recursive architecture of the network. | D |
| | **Explanantion:** $\checkmark$ Explanation of Correct Answer (D): In RVNNs, gradients flow backward through the tree by recursively applying the chain rule from parent nodes down to children, a process known as Backpropagation Through Structure. $\times$ Explanation of Distractors: A: Incorrect — This describes Backpropagation Through Time (BPTT) used in RNNs, not RVNNs. B: Incorrect — This is a characteristic of CNNs, not applicable to recursive networks. C: Incorrect — Standard feedforward networks use layered backpropagation, which doesn't apply to the tree-like structure of RVNNs. | |
| 3 | **Deep-Reinforcement Learning >> Recursive Neural Network** QNo. 3: How does a Recursive Neural Network (RvNN) process input in a hierarchical or tree-like structure? A. It scans the input linearly from left to right and encodes each element using a time-based memory mechanism to retain context. B. It processes each node independently and combines all representations into a final output layer for prediction or classification. C. It combines child node representations recursively using shared weights until a root representation is formed. D. It breaks the input into equal-sized segments, processes them in parallel, and then merges the results through attention layers at the end. | C |
| | **Explanantion:** $\checkmark$ Explanation of Correct Answer (C): RVNNs operate bottom-up by recursively merging representations of child nodes into parent nodes, forming a tree structure with shared weights until the entire structure is encoded in the root node. $\times$ Explanation of Distractors: A: Incorrect — This describes how Recurrent Neural Networks (RNNs) process sequential data, not tree-structured data. B: Incorrect — RVNNs depend on the recursive combination of nodes, not independent processing with a final merge. D: Incorrect — This reflects how transformers or parallelized models operate, not the recursive structure which doesn't process in parallel based on fixed segments. | |
| 4 | **Deep-Reinforcement Learning >> Recursive Neural Network** QNo. 4: How does a Recursive Neural Network (RvNN) differ from a Recurrent Neural Network (RNN)? A. RVNNs process hierarchical structures like trees, while RNNs process sequential data step-by-step using temporal recurrence between elements. B. RVNNs use convolutional layers to handle 2D data, whereas RNNs apply linear transformations to time series signals. C. RVNNs require labeled sequential data to train, while RNNs are used mostly for unsupervised learning tasks like clustering. D. RVNNs use fixed-length inputs only, whereas RNNs work with tree-like structures that vary in depth and composition. | A |
| | **Explanantion:** $\checkmark$ Explanation of Correct Answer (A): Recursive Neural Networks are designed to work on structured data, like trees, combining representations of child nodes, while RNNs are used for linear sequences such as text or time series. $\times$ Explanation of Distractors: B: Incorrect — This incorrectly assigns CNN functionality to RVNNs and mischaracterizes RNNs as purely linear processors. C: Incorrect — Both models can handle supervised learning; RNNs are not primarily used for clustering. D: Incorrect — RVNNs actually handle variable-depth trees, not fixed-length inputs, whereas RNNs handle fixed-length sequences better than tree structures. | |
| 5 | **Deep-Reinforcement Learning >> Recursive Neural Network** QNo. 5: What is a Recursive Neural Network (RvNN)? A. A neural network that applies the same set of weights recursively over a hierarchical tree structure to learn representations of structured data like parse trees. B. A network that uses recurrent connections to process time-series data sequentially using feedback loops for each time step in the sequence. C. A neural model that uses convolutional layers to detect spatial features in grid-like data such as images or audio spectrograms. D. A fully connected neural network that passes input through multiple dense layers to perform classification on fixed-length feature vectors. | A |
| | **Explanantion:** $\checkmark$ Explanation of Correct Answer (A): Recursive Neural Networks apply the same weights to nodes in a tree structure, recursively combining child representations into parents, making them ideal for hierarchical data like natural language parse trees or scene structures. $\times$ Explanation of Distractors: B: Incorrect — This describes Recurrent Neural Networks (RNNs), which process sequences linearly, not hierarchically. C: Incorrect — This refers to Convolutional Neural Networks (CNNs), used for spatial feature extraction, not recursive structures. D: Incorrect — This is a general feedforward neural network, which lacks the recursive or hierarchical capabilities of an RVNN. | |